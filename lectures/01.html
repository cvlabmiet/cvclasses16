<!-- Any section element inside of this container is displayed as a slide -->
<div class="slides">
    <section data-markdown>
	# Computer Vision
	## Inception
	---
	Roman Golovanov
    </section>
	
	<section data-markdown>
	## Course structure
	
	1. OpenCV Library
	1. Image Segmentation
	1. Edge Detection
	1. Movement Detection
	1. Feature Detection
	1. Feature Matching
	1. Object Tracking
	1. Stereovision
	</section>
	
	<section>
		<section data-markdown>
		### Image Segmentation

		In computer vision, image segmentation is the process of partitioning a digital image into 
		multiple segments (sets of pixels, also known as super-pixels).

		![An example of relativity of segmentation](https://cloud.githubusercontent.com/assets/14174584/19366759/07e061d2-91a1-11e6-93fa-2b31884aa563.png)
		</section>
        
		<section data-markdown>
		### First objective

		The first objective is to decompose the image into parts for further analysis.
		In simple cases, the environment might be well enough controlled
		so that the segmentation process reliably extracts only the parts that
		need to be analyzed further.
        </section>
        
        <section data-markdown>
		### Second objective

		The second objective of segmentation is to perform a change of representation. 
		The pixels of the image must be organized into higher-level units that are 
		either more meaningful or more effcient for further analysis (or both).
        </section>
        
		<section data-markdown>
		### Methods

		Some of the main methods of image segmentation are:

		-	Thresholding
		-	Clustering methods
		-	Histogram-based methods
		-	Edge detection
		-	Region-growing methods
		-	Graph partitioning methods
		-	Watershed transformation
		-	Semi-automatic segmentation
		-	Trainable segmentation
		-	...
        </section>	

        <section data-markdown>
		### Applications

		Some of the practical applications of image segmentation are:

		- Content-based image retrieval
		- Machine vision
		- Medical imaging
		- Object detection
		- Recognition Tasks
		- Traffic control systems
		- Video surveillance
		- ...

		Several general-purpose algorithms and techniques have been developed for image segmentation.
		To be useful, these techniques must typically be combined with a domain's specific knowledge
		in order to effectively solve the domain's segmentation problems.
		</section>
        
        <section data-markdown>
		### Problems

		- Segmentation benchmarking
		- The lack of universal descriptors and methods
		- Noised images
		- ...
		</section>
		
		<section data-markdown>
		### Segmentation benchmarking

		Several segmentation benchmarks are available for comparing the performance of segmentation methods 
		with the state-of-the-art segmentation methods on standardized sets:

		- Prague On-line Texture Segmentation Benchmark
		- The Berkeley Segmentation Dataset and Benchmark
		</section>
		
		<section data-markdown>
		### The lack of universal descriptors and methods

		The main problem is the lack of universal descriptors. 
		The segmentation in itself is quite simple, but the lack of meaningful descriptors complicates the task of segmentation.
		</section>
        
        <section data-markdown>
        ### An example of relativity of segmentation
        
        ![An example of relativity of segmentation](https://cloud.githubusercontent.com/assets/14174584/19366764/0812a002-91a1-11e6-8f5b-27a5b05105ca.png)
		</section>
        
        <section data-markdown>
        ### Watershed based segmentation
        
        ![Watershed based segmentation](https://cloud.githubusercontent.com/assets/14174584/19366760/07e089b4-91a1-11e6-9a4f-22d854e3057b.jpg)
		</section>
        
        <section data-markdown>
        ### Segmentation using k-means clustering
        
        ![Segmentation using k-means clustering](https://cloud.githubusercontent.com/assets/14174584/19366762/080d6ad8-91a1-11e6-9cc0-d950679f50be.jpg)
		</section>
        
        <section data-markdown>
        ### Thresholding methods such as Otsu's method
        
        ![Thresholding methods such as Otsu's method](https://cloud.githubusercontent.com/assets/14174584/19366761/07fd035a-91a1-11e6-8522-c6db4450855b.jpg)
		</section>
        
	</section>
	
	<section>
		<section data-markdown>
		### Edge Detection
		
		Edge detection is a fundamental tool in image processing, machine vision and computer vision, particularly in the areas of feature detection and feature extraction.

		The edge reflects important features of the image, and therefore, the objectives of the image conversion curves are set:

		* selection the essential characteristics of the image
		* reducing the amount of information for subsequent analysis
		</section>

		<section data-markdown>
		###Canny edge detector
		The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images.
		The Canny algorithm is adaptable to various environments. Its parameters allow it to be tailored to recognition of edges of differing characteristics depending on the particular requirements of a given implementation.
		![Example of Canny](https://cloud.githubusercontent.com/assets/14174584/19366747/fb427af0-91a0-11e6-9036-4f2bbafa8376.png)

		</section>		
	</section>
	
	<section>
		<section data-markdown>
		### Movement Detection

		In video surveillance, motion detection refers to the capability of the surveillance system to detect motion and capture the events. 
		Motion detection is usually a software-based monitoring algorithm which, when it detects motions will signal the surveillance camera to begin capturing the event. 
		Also called activity detection. An advanced motion detection surveillance system can analyze the type of motion to see if it warrants an alarm.
		</section>
		
		<section data-markdown>
		### Movement Detection

		There are many approaches for motion detection in a continuous video stream.
		All of them are based on comparing of the current video frame with one from the previous frames or with background.

		One of the most common approaches is to compare the current frame with the previous one. 
		It's useful in video compression when you need to estimate changes and to write only the changes, not the whole frame. 
		But it is not the best one for motion detection applications. 
		</section>

		<section data-markdown>
		### Movement Detection

		![Example of the algorithm's working](https://cloud.githubusercontent.com/assets/14174584/19366772/0b3f86f0-91a1-11e6-9740-8dd2fa24f294.jpg)

		From the above picture we can see the disadvantages of the approach. If the object is moving smoothly we'll receive small changes from frame to frame. 
		So, it's impossible to get the whole moving object. Things become worse, when the object is moving so slowly, when the algorithms will not give any result at all.
		</section>

		<section data-markdown>
		### Movement Detection

		There is another approach. It's possible to compare the current frame not with the previous one but with the first frame in the video sequence.
		So, if there were no objects in the initial frame, comparison of the current frame with the first one will give us the whole moving object independently of its motion speed.
		</section>

		<section data-markdown>
		### Movement Detection

		The most efficient algorithms are based on building the so called background of the scene and comparing each current frame with the background.

		![Example](https://cloud.githubusercontent.com/assets/14174584/19366771/0b3eef74-91a1-11e6-812a-078ad0045893.jpg)
		</section>

		<section data-markdown>
		### Movement Detection

		![Motion detection](https://cloud.githubusercontent.com/assets/14174584/19366770/0b3df0d8-91a1-11e6-80d2-5885f135cb82.jpg)
		</section>
	</section>
	
	<section>
		<section data-markdown>
		### Feature Detection
		
		In computer vision and image processing the concept
		of feature detection refers to methods that aim at
		computing abstractions of image information and making
		local decisions at every image point whether there is
		an image feature of a given type at that point or not.
		The resulting features will be subsets of the image domain,
		often in the form of isolated points, continuous curves or connected regions.

		</section>
		
		<section data-markdown>
		### Feature Detection
		
		Types of image features:
		* Edges;
		* Corners / interest points;
		* Blobs / regions of interest or interest points;
		* Ridges;
		</section>

		<section data-markdown>
		### Feature Detection

		Examples: Searching of feature points on human face
		![Feature points on face](https://cloud.githubusercontent.com/assets/14174584/19366752/fe8d9578-91a0-11e6-81eb-693ecb8ba983.jpg)
		</section>

		<section data-markdown>
		### Feature Detection

		Examples: Searching of feature points on geometric angles
		![Geometric angles](https://cloud.githubusercontent.com/assets/14174584/19366753/fe8e2056-91a0-11e6-91e0-65fd66863191.jpg)
		</section>

	</section>

	<section>
		<section data-markdown>
		### Feature Matching

		Feature matching is finding corresponding features
		in two or more images.
		
		Feature matching applications are:
		* Stitching image panoramas
		* Tracking objects by detection
		* Object recognition
		</section>
		
		<section data-markdown>
		### Feature Matching
		Example: point correspondence between images (red circles are incorrect matches).
		![Point correspondence between images](https://cloud.githubusercontent.com/assets/14174584/19366756/02b1f112-91a1-11e6-8250-449b3d998992.jpg)
		</section>		

		<section data-markdown>
		### Panorama stitching example
		![panorama example](https://cloud.githubusercontent.com/assets/14174584/19366757/02b21bd8-91a1-11e6-9cbb-9bf4b7598157.jpg)  
		</section>

		<section data-markdown>
		### Feature matching difficulties
		  
		* Detecting type I errors (false positives)
		* Matching large amounts of features
		</section>
	</section>
	
	<section>
		<section data-markdown>
		### Object Tracking
		
		Objects tracking are important components of many computer vision applications, including activity recognition, traffic monitoring and etc. 
		
		The problem of object tracking can be divided into two parts:
		1. Detecting objects in frame
		1. Associating the detections corresponding to same object over time
		
		![Example of tracking object](https://cloud.githubusercontent.com/assets/14174584/19366978/f05af06c-91a1-11e6-954d-d5d1438ee586.png)
		</section>
		
		<section data-markdown>
		### Problems of Object Tracking

		* Noise in frame
		* Loss of information caused by 3D world on a 2D image
		* Changes of illumination
		* Complex object shapes
		* Multiple objects
		* etc
		</section>
		
		<section data-markdown>
		### Detecting objects in frame
		Every tracking method requires an object detection mechanism either in every frame or when the object first appears in the video.
		1. Detection with algorithms of computer vision
			* Point detector (Harris, SIFT)
			* Supervised Learning (SVM, CNN and enc)	
		1. Detection based on object's color
		1. Manual selection of object

		</section>

		<section data-markdown>
		### Associating the detections corresponding to the same object over time
		#### Methods:
		* Absolute difference of neighbor frames
		* Lucas–Kanade method
		* Detection objects in each frame
		* ...
		
		![Tracking object](https://cloud.githubusercontent.com/assets/14174584/19366778/0f9a432a-91a1-11e6-90e1-7f65124aa05f.png)
		</section>

		<section data-markdown>
		### Absolute difference of neighbor frames

		![Absolute difference](https://cloud.githubusercontent.com/assets/14174584/19366779/0fb00ee4-91a1-11e6-87c3-49d257df8916.png)
		</section>

		<section data-markdown>
		### Lucas–Kanade method
		Lucas–Kanade method is a widely used differential method for optical flow estimation. 
		
		![Lucas–Kanade Method](https://cloud.githubusercontent.com/assets/14174584/19366777/0f96ac2e-91a1-11e6-8cb2-8e9f0830cf41.jpg)
		</section>
	
		<section data-markdown>
		### Detection objects in each frame		
		Objects detected in consecutive frames are represented by points, and the association of the points is based on previous object state which can include object potion and motion.
		</section>	
	</section>
	
	<section>
		<section data-markdown>
        ### Stereovision        
        Environment and object reconstruction      

        ![reconstruction](https://cloud.githubusercontent.com/assets/14174584/19366815/2c4cbac0-91a1-11e6-9adc-daedc71de2d7.png)
		</section>
		
		<section data-markdown>
        ### Stereovision
        Object detection and tracking       

        ![tracking](https://cloud.githubusercontent.com/assets/14174584/19366816/2c4ed47c-91a1-11e6-8170-94fb95316624.png)
		</section>
        
        <section data-markdown>
        ### Stereovision
        Autonomus robotic navigation    

        ![kasjhdbfsfbd](https://cloud.githubusercontent.com/assets/14174584/19366814/2c4c1700-91a1-11e6-9c13-c8f6ebb80a2b.png)
		</section>
        
	</section>
	
	<section data-markdown>
	# OpenCV library
	
	<!-- Based on materials from http://www.cs.iit.edu/~agam/cs512/lect-notes/opencv-intro/opencv-intro.html -->
	</section>

	<section>
		<section data-markdown>
		## Introduction
		
		[OpenCV (Open Source Computer Vision Library)](http://opencv.org/about.html)
		
		is an open source computer vision and machine learning software library.
		
		OpenCV was built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in the commercial products.
		
		Being a BSD-licensed product, OpenCV makes it easy for businesses to utilize and modify the code.
		
		...
		</section>
		
		<section data-markdown>
		### History
		![OpenCV History](https://cloud.githubusercontent.com/assets/14174584/19366744/f9203320-91a0-11e6-971b-1203828669e4.png)
		</section>
		
		<section data-markdown>
		### Modules
		* _core_ - Core functionality
		* _imgproc_ - Image processing
		* _imgcodecs_ - Image file reading and writing
		* _videoio_ - Media I/O
		* _highgui_ - High-level GUI
		* _video_ - Video Analysis
		* _calib3d_ - Camera Calibration and 3D Reconstruction
		* _features2d_ - 2D Features Framework
		* _objdetect_ - Object Detection
		* ...
		* _cudaXXX_ - Modules optimized for CUDA
		</section>
		
		<section data-markdown>
		### Structure
		![OpenCV Structure](https://cloud.githubusercontent.com/assets/14174584/19366743/f90ef2e0-91a0-11e6-8213-57fb18e1a727.png)
		</section>
		
		<section data-markdown>
		### Naming Conventions
		* OpenCV uses mixed-case style identifiers for external functions, types and class methods.
		* Class names start with a capital letter.
		* methods' and functions' names start with a small latter, unless they are named after the author of the algorithm, e.g. cv::Sobel().
		* Macros and enumeration constants are written with all capital letters. Words are separated by underscore.
		* All external functions and classes must use CV_EXPORTS, otherwise there will be linking errors on Windows.
		</section>
		
		<section data-markdown>
		### Naming Conventions cont.
		**Functions**:
		
			cv::ActionTargetMod(input,..., output,..., flag|optional)

			Action = the core functionality (e.g. set, create)
			Target = the target image area (e.g. contour, polygon)
			Mod    = optional modifiers (e.g. argument type)
			
			E.g.: cv::medianBlur(...)

		**Matrix data types**:
		
			CV_<bit_depth>(S|U|F)C<number_of_channels>

			S = Signed integer
			U = Unsigned integer
			F = Float 

			E.g.: CV_8UC1 means an 8-bit unsigned single-channel matrix,
			
			      CV_32FC2 means a 32-bit float matrix with two channels.
		</section>
		
		<section data-markdown>
		### Compilation
		
		* Linux:
		> g++ hello-world.cpp -o hello-world -I /usr/local/include/opencv -L /usr/local/lib -lm -lcv -lhighgui -lcvaux
			
		* Windows:
		In the project preferences set the path to the OpenCV header files and the path to the OpenCV library files.
		
		</section>
	</section>

	<section>
		<section data-markdown>
		## Graphical User Interface
		</section>
		
		<section data-markdown>
		### Window management
		```
		// Creates a window
		const std::string windowName = "My Window";
		cv::namedWindow(windowName, WINDOW_AUTOSIZE);
		
		// Load and show image in window
		const cv::Mat img = cv::imread("test.bmp");
		cv::imshow(windowName,img);
		
		// Operations with window
		cv::moveWindow(windowName, 100 /*x*/, 200 /*y*/);
		cv::resizeWindow(windowName, 300 /*width*/, 400 /*height*/);
		cv::updateWindow(windowName);
		
		// Close window
		cv::destroyWindow(windowName);
		cv::destroyAllWindows(windowName);
		```		
		</section>
		
		<section data-markdown>
		### Input Handling
		
		OpenCV highgui module allows to flexibly handle mouse and keyboard events.
		
		</section>
		
		<section data-markdown>
		#### Mouse Events
		```
		// setup mouse handler
		cv::setMouseCallback(windowName, onMouse, static_cast<void*>(&m_mouseLine));

		// define handler which will track mouse click and move
		void onMouse(int event, int x, int y, int flags, void* param) {
		  auto& line = *static_cast<std::pair<cv::Point, cv::Point>*>(param);
		  switch (event) {
			case CV_EVENT_LBUTTONDOWN:
			case CV_EVENT_RBUTTONDOWN:
			  line.first = { x, y };
			  return;
			case CV_EVENT_MOUSEMOVE:
			...
		  }
		}
		```
		</section>
		
		<section data-markdown>
		#### Keyboard Events
		
		* The keyboard does not have an event handler.

		* Get keyboard input without blocking:
		```
		int key=cvWaitKey(10); // wait 10ms for input
		```
		* Get keyboard input with blocking:
		```
		int key=cvWaitKey(0); // wait indefinitely for input
		```
		</section>
		
		<section data-markdown>
		#### UI Controls
		
		Define a trackbar handler:
		```
		void trackbarHandler(int pos) {
		  printf("Trackbar position: %d\n", pos);
		}
		```
			
		Register the handler:
		```
		int val = 25; // shall be alive while window is active
		const int maxVal = 100;
		cv::createTrackbar("bar1", "win1", &val, maxVal, trackbarHandler);
		```

		Get the current trackbar position:
		```
		const int pos = cv::getTrackbarPos("bar1", "win1");
		```
		Set the trackbar position:
		```
		cv::setTrackbarPos("bar1", "win1", 25);
		```
		</section>
		
		<section data-markdown>
		#### Drawing Primitives
		
		* cv::circle(...) - draws a circle
		* cv::ellipse(...) - draws an ellipse or arc
		* cv::line(...) - draws a line, see also **cv::LineIterator**
		* cv::arrowedLine(...) - draws an arrow
		* cv::rectangle(...) - draws a rectangle
		* cv::drawContours(...) - draws outlines or filled contours
		* cv::putText(...)  draws a text string
		
		</section>
		
		<section data-markdown>
		### Demo
		
		See lesson1.vcproj
		</section>
	</section>

	<section>
		<section data-markdown>
		## Basic Data Structures
		
		|           |          |
		|-----------|------------------------|
		| cv::Point | 2D Point |
		| cv::Size  | 2D Size structure |
		| cv::Rect  | 2D rectangle object |
		| cv::Mat   | matrix or image object |
		
		</section>
		
		<section data-markdown>
		### cv::Point{2|3,i|f|d}
		
		Members:
		```
		T x; // x coordinate
		T y; // y coordinate
		```
		
		Functions:
		```cpp
		dot(cv::Point<T>& pt) = x * pt.x + y * pt.y
		ddot(cv::Point<T>& pt) = (double)x * pt.x + (double)y * pt.y
		cross(cv::Point<T>& pt) = (double)x * pt.y - (double)y * pt.x
		inside(cv::Rect<T>& rect) = rect.contains(*this)
		```
		
		Operators:
		```
		+, -, +=, -= (cv::Point<T>& pt);
		*, /, *=, /= ({double|int} val);
		```
		</section>
		
		<section data-markdown>
		### cv::Size{2,i|f|d}
		
		Members:
		```
		T width;
		T height;
		```
		
		Functions:
		```
		area() = width * height
		```
		</section>
		
		<section data-markdown>
		### cv::Rect{2,i|f|d}
		
		Members:
		```
		T x, y;
		T width, height;
		```
		
		Functions:
		```
		tl() = cv::Point{x, y}
		br() = cv::Point{x + width, y + height}
		size() = cv::Size{width, height}
		area() = width * height
		contains(cv::Point& pt) = x <= pt.x && pt.x < x + width 
		                       && y <= pt.y && pt.y < y + height
		```		
		</section>
	</section>

	<section>
		<section data-markdown>
		## Work with cv::Mat
		
		C++ n-dimensional array class
		
		### Main members:
		```
		int flags; // depth, number of channels, cont. flag
		int dims; // dimensionality, >= 2
		int rows, cols; // number of rows and cols or (-1, -1) if dims > 2
		uchar* data; // pointer to the data
		int* refcount; // pointer to reference counter
		```
		
		</section>
		
		<section data-markdown>
		### Basic Operations
		#### Allocation
		```
		cv::Mat m;
		m.resize(30,50);
		m.reserve({100, 200});
		```
		#### Release
		```
		m.resize({0, 0});
		m.release();
		```
		#### Sharing - no data copying
		```
		cv::Mat m2;
		m2.assignTo(m); // add ref and share data
		cv::Mat m4{m1, cv::Range{0, 4}, cv::Range::all()};
		cv::Mat m5{m1, cv::Rect{10, 20, 5, 7}};
		```
		#### Init
		```
		cv::Mat m{2, 2, CV_64F, {{1, 2}, {3, 4}}};
		cv::Mat m2{10, 20, CV_8UC1, cv::Scalar{9}};
		m2.create(20, 40, CV_8UC(5));
		```
		</section>
		
		<section data-markdown>
		#### Sample of Init
		
		Code below initializes matrix with Flag of Russia
		
		```
		const auto& redColor   = cv::Scalar{   0,   0, 255 };
		const auto& blueColor  = cv::Scalar{ 255,   0,   0 };
		const auto& whiteColor = cv::Scalar{ 255, 255, 255 };

		const auto& flagSize = cv::Size{ 9, 6 };

		cv::Mat m(flagSize, CV_8UC3, redColor);
		m.rowRange(flagSize.height / 3, flagSize.height * 2 / 3).setTo(blueColor);
		m.rowRange(0, flagSize.height / 3).setTo(whiteColor);
		```
		
		![Flag of Russia in cv::Mat](https://cloud.githubusercontent.com/assets/14174584/19366742/f8eeb2f0-91a0-11e6-909c-70225ce991c0.png)
		</section>
		
		<section data-markdown>
		### Access Elements
		```
		cv::Mat m({ 10, 15 }, CV_8UC1, cv::Scalar{ 0 });
		
		// operator (...)
		m(cv::Rect{ 5, 7, 3, 3 }).setTo(127);
		m(cv::Range{ 3, 7 }, cv::Range{ 2, 9 }).setTo(255);
		
		// .at(...), .ptr(...)
		m.at< char >(cv::Point{ 3, 5 }) = 64;
		const auto p = m.ptr< char >(cv::Point{4, 8});
		
		// .rowRange(...), .colRange(...)
		m.rowRange(0, 5).setTo(cv::Scalar{255});
		
		// .row(...), .col(...)
		m.row(8).setTo(cv::Scalar{127});
		
		// .begin(), .end() iterators
		for(auto it = m.begin(); it != m.end(); ++it)
			func(*it);		
		```
		</section>
		
		<section data-markdown>
		### Matrix Expressions
		* Addition, subtraction, negation: A+B, A-B, A+s, A-s, s+A, s-A, -A
		* Scaling: A*alpha
		* Per-element multiplication and division: A.mul(B), A/B, alpha/A
		* Matrix multiplication: A*B
		* Transposition: A.t() (means AT)
		* Bitwise logical operations: A op B, A op s, s op A, ~A, where op is one of :  &, |, ^.
		* Element-wise minimum and maximum: min(A, B), min(A, alpha), max(A, B), max(A, alpha)
		* Element-wise absolute value: abs(A)
		* Cross-product, dot-product: A.cross(B) A.dot(B)
		* Others
		</section>
	</section>

	<section>
		<section data-markdown>
		## Work with Video
		</section>
	
		<section data-markdown>
		### Capturing Video Stream
		cv::VideoCapture is class for capturing from video files, image sequences or cameras.
		
		Methods:
		* open(...) - file name or device id (camera id)
		* isOpened() - checks whether capture is opened
		* release() - closes video file or capturing device
		* grab() - grabs the next frame from video file or device
		* retrieve(...) - decodes and returns grabbed video frame
		* read(...), operator >> - grab + retrieve
		* get(int) - returns specified capture property
		* set(int, double) - sets a property
		
		</section>
		
		<section data-markdown>
		### Frame Information
		
		Following set of properties is available for retrieving and changing:
		```
		CV_CAP_PROP_POS_MSEC Current position of the video file or video capture timestamp.
		CV_CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next.
		CV_CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0 - start, 1 - end.
		CV_CAP_PROP_FRAME_WIDTH Width of the frames in the video stream.
		CV_CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream.
		CV_CAP_PROP_FPS Frame rate.
		CV_CAP_PROP_FOURCC 4-character code of codec.
		CV_CAP_PROP_FRAME_COUNT Number of frames in the video file.
		CV_CAP_PROP_FORMAT Format of the Mat objects returned by retrieve() .
		CV_CAP_PROP_MODE Backend-specific value indicating the current capture mode.
		```
		
		Available for cameras only:
		```
		CV_CAP_PROP_BRIGHTNESS Brightness of the image.
		CV_CAP_PROP_CONTRAST Contrast of the image.
		CV_CAP_PROP_SATURATION Saturation of the image.
		CV_CAP_PROP_HUE Hue of the image.
		CV_CAP_PROP_GAIN Gain of the image.
		CV_CAP_PROP_EXPOSURE Exposure.
		CV_CAP_PROP_CONVERT_RGB Indicates whether images should be converted to RGB.
		CV_CAP_PROP_WHITE_BALANCE Currently not supported
		CV_CAP_PROP_RECTIFICATION Rectification flag for stereo cameras
		```

		</section>
		
		<section data-markdown>
		### Writing Video
		cv::VideoWriter class is used for writing video.
		
		Methods:
		* open(fileName, fourcc, fps, frameSize, isColor) - initializes/reinitializes writer
		* isOpened() - return true if writer has been initialized
		* write(image) - writes the next video frame
		</section>
		
		<section data-markdown>
		### Capturing and writing demo
		
		TODO: write simple code with capturing video from camera and writing it to the file
		</section>
	</section>

	<section>
		<section data-markdown>
		## Utilities
		</section>
		
		<section data-markdown>
		### cv::CommandLineParaser
		
		Designed for command line parsing.
		```
		const std::string keys = "{help h usage ?|  | print this message}"
		                         "{@image        |  | image to process }";

		cv::CommandLineParser parser(argc, argv, keys);
		parser.about("Computer Vision Classes Demo v1.0.0");
		if (parser.has("help")) {
		    parser.printMessage();
		}

		const auto& img = parser.get< cv::String >("@image");
		if (!parser.check()) {
		    parser.printErrors();
		} else {
		    std::cout << "Path to image: " << img << "\n";
		}
		```
		</section>
		<section data-markdown>
		### cv::TickMeter
		
		The class computes passing time by counting the number of ticks per second.
		
		```
		TickMeter tm;
		tm.start();
		// do something ...
		tm.stop();
		std::cout << tm.getTimeSec();
		std::cout << tm.getTimeTicks();
		std::cout << tm.getTimeMilli();
		std::cout << tm.getTimeMicro();
		```		
		</section>
		
		<section data-markdown>
		
		### Utility Functions
		
		Align pointers and size, calculate norm, get system information and many other helpful things.
		
		</section>
	</section>
	
	<section>		
		<section data-markdown>
		### Resources
		* http://opencv.org/about.html
		* [Introduction to programming with OpenCV](http://www.cs.iit.edu/~agam/cs512/lect-notes/opencv-intro/opencv-intro.html)
		* [OpenCV Coding Style](http://code.opencv.org/projects/opencv/wiki/Coding_Style_Guide)
		* [Learning OpenCV, G.Bradski and A.Kaehler](http://www.bogotobogo.com/cplusplus/files/OReilly%20Learning%20OpenCV.pdf)
		* [OpenCV Tutorials](http://docs.opencv.org/3.0-beta/doc/tutorials/tutorials.html)
		</section>
	</section>
	
    <section data-markdown>
        ## Thank You!
    </section>
</div>
